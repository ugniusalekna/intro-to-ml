{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generatyviniai neuroniniai tinklai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generatyviniai adversariniai tinklai (angl. generative adversarial networks, GANs) yra dar viena dirbtinių neuroninių tinklų architektūra, naudojama naujų duomenų (vaizdo, garso) generavimui. \n",
    "\n",
    "- Idėja buvo prisatyta 2014 m. mokslininko Ian Goodfellow ir jo kolegų."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "<img src=\"https://raw.githubusercontent.com/ugniusalekna/intro-to-ml/main/images/gans_paper.png\" alt=\"gans-paper\" width=\"35%\">\n",
    "<p><strong>1.14 pav., Straipsnis, kuriame pristatyti GANs </strong></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Iki GAN tinklų atsiradimo generatyviniai modeliai nė neegzistavo. Kai kurie eksperimentai buvo atliekami su autokoderiais, dažnai duodančiais neryškius vaizdus, artefaktus. \n",
    "\n",
    "- Bet žmonės jau žinojo, kaip sukurti galingus vaizdų klasifikatorius! 2012 m. pasirodęs *AlexNet* modelis buvo pirmasis modelis, sutriuškinęs savo konkurentus vaizdo klasifikavimo uždaviniuose. \n",
    "\n",
    "- Goodfellow idėja buvo, užuot kūrus galingą generatorių, paimti jau egzistuojančio klasifikatoriaus (kurį jis pavadino diskriminatoriumi) architektūrą bei jį panaudoti *apmokant kitą modelį*, atsakingą už naujų duomenų generavimą.\n",
    "\n",
    "- Pagrindinė GAN inovacija – generatoriaus užduotis ne tiesiogiai sukurti duomenis, panašius į apmokymo aibę (labai sunki užduotis), bet sukurti tokius duomenis, kurie galėtų apgauti diskriminatorių, klasifikuojant juos kaip tikrus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pagrindiniai komponentai\n",
    "\n",
    "**Generatorius (G)**: Generatoriaus tinklo tikslas - sukurti duomenų pavyzdžius, kurie nesiskirtų nuo tikrų duomenų. Jis pradeda su atsitiktiniu triukšmo vektoriumi ir paverčia jį duomenų pavyzdžiu. Generatoriaus tikslas - sukurti išvestį, kuri būtų kuo artimesnė tikrajam duomenų pasiskirstymui.\n",
    "\n",
    "**Diskriminatorius (D)**: Diskriminatorius yra binarinis klasifikatorius, kuriuo bandoma atskirti tikruosius duomenų pavyzdžius nuo generatoriaus sukurtų pavyzdžių. Jo įvestis tikras arba sugeneruotas duomenų rinkinio pavyzdys, o išvestis – tikimybė, nurodanti, ar pavyzdys yra klasifikuojamsa kaip tikras, ar kaip netikras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarinio mokymosi procesas\n",
    "\n",
    "- GAN tinklo apmokymas yra minmax optimizavimo uždavinys tarp generatoriaus ir diskriminatoriaus\n",
    "\n",
    "- Mokymosi pradžioje generatorius pateikia akivaizdžiai netikrus duomenis, todėls diskriminatorius greitai išmoksta nustatyti, kad jie yra netikri\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"https://raw.githubusercontent.com/ugniusalekna/intro-to-ml/main/images/gans_1.png\" alt=\"gans-example\" width=\"85%\">\n",
    "</div>\n",
    "\n",
    "- Tęsiantis mokymosi procesui, generatorius vis labiau artėja prie sugeneruotų duomenų, galinčių apgauti diskriminatorių.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"https://raw.githubusercontent.com/ugniusalekna/intro-to-ml/main/images/gans_2.png\" alt=\"gans-example\" width=\"85%\">\n",
    "</div>\n",
    "\n",
    "- Galiausiai, jei generatoriaus apmokymas pavyksta, diskriminatorius vis prasčiau atskiria tikrą duomenų atvejį nuo netikro. Jis pradeda klasifikuoti netikrus duomenis kaip tikrus, ir jo tikslumas mažėja.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"https://raw.githubusercontent.com/ugniusalekna/intro-to-ml/main/images/gans_3.png\" alt=\"gans-example\" width=\"85%\">\n",
    "</div>\n",
    "\n",
    "- GAN architektūros schema atrodo daugmaž taip:\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"https://raw.githubusercontent.com/ugniusalekna/intro-to-ml/main/images/gans_architecture.png\" alt=\"gans-architecture\" width=\"80%\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Netikties funkcija\n",
    "\n",
    "- Straipsnyje, kuriame pristatyti GANs, netikties funkcija apibrėžiama formule:\n",
    "\n",
    "$$\n",
    "L(G, D) = \\frac{1}{m} \\sum_{i=1}^{m} [\\log D(x^{(i)})] + \\frac{1}{m} \\sum_{i=1}^{m} [\\log(1 - D(G(z^{(i)})))] \n",
    "$$\n",
    "\n",
    "- Generatorius ($G$) stengiasi minimizuoti šią funkciją, o diskriminatorius ($D$) stengiasi ją maksimizuoti (nes norime \"apgauti\" diskriminatorių). Tai yra kiek kitokia optimizavimo forma, nuo mums įprastos $\\min_{w} f(w)$:\n",
    "\n",
    "$$\n",
    "\\min_{G} \\max_{D} L(G, D)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daugdaros didelio matmens erdvėse\n",
    "\n",
    "- Kiekvieną vaizdą galime įsivaizduoti kaip tašką didelio matmens erdvėje – kiekvieno pikselio vertė atitinka tašką ant atitinkamos dimensijos ašies. Pvz., turėdami vieno kanalo (*grayscale*) nuotrauką, susidedančią iš 3 pikselių, šių nuotraukų erdvę galime geometriškai pavaizduoti 3D kubu:\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"https://raw.githubusercontent.com/ugniusalekna/intro-to-ml/main/images/manifold_hypercube.jpg\" alt=\"manifold-hypercube\" width=\"65%\">\n",
    "</div>\n",
    "\n",
    "- Tuo tarpu, 256x256 vieno kanalo vaizdą galima pavaizduoti 65 536 matmenų hiperkube.\n",
    "\n",
    "- Didžioji dauguma tokio hiperkubo taškų yra triukšmingi, beprasmiai vaizdai. Reikšmingi vaizdai, pavyzdžiui, nuotraukos ar parašyti puslapiai, šioje erdvėje pasitaiko itin retai.\n",
    "\n",
    "- Daugdaros – tai mažesnio matavimo poerdviai aukšto matmens erdvėse, turintys mažiau laisvės laipsnių (t.y. gali būti atvaizduoti į mažesnio matavimo erdves). \n",
    "\n",
    "- Manoma, jog prasmingi vaizdai yra išsidėstę mažesnio matmens poerdviuose šioje didelio matmens erdvėje (hiperkube). Pavyzdžiui, vaizdų, kuriuose vaizduojamas žmogaus veidas su skirtingomis išraiškomis, rinkinys yra kažkur „veidų daugdaroje“, kadangi visų tokių nuotraukų pikselių pasiskirstymai turėtų būti bent kiek panašūs. Suradus tokias daugdaras bei judant jomis, galime matyti sklandžiai (tolydžiai) besikeičiančių vaizdų animacijas.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"https://raw.githubusercontent.com/ugniusalekna/intro-to-ml/main/images/manifold_transitions.jpg\" alt=\"manifold-transitions\" width=\"65%\">\n",
    "</div>\n",
    "\n",
    "\n",
    "Local Coordinates and Degrees of Freedom: The idea of local coordinate systems on the manifold is discussed. While the high-dimensional space offers many directions of movement, the manifold constrains movement to fewer degrees of freedom, akin to how an ant moving on a line (one-dimensional manifold) perceives the world.\n",
    "Natural Data and Manifolds: The transcript highlights that natural data, like human height and weight, often lie on or near low-dimensional manifolds within high-dimensional spaces, indicating underlying correlations or constraints.\n",
    "Generative Models and Manifold Learning: Finally, it discusses how generative models like GANs and VAEs learn to approximate these image manifolds. They map a low-dimensional latent space to the high-dimensional space of images, essentially learning the manifold structure. This mapping is optimized to allow control over image features, which is a key area of ongoing research."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
