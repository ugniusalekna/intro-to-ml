{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Konvoliuciniai neuroniniai tinklai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- David H. Hubel ir Torsten Wiesel 1958 m. atliko keletą eksperimentų su katėmis, kurie suteikė esminių įžvalgų apie regos žievės struktūrą. \n",
    "\n",
    "- Jie parodė, kad daugelis regos žievės neuronų turi mažą vietinį receptorinį lauką, t. y. jie reaguoja tik į ribotoje regos lauko srityje esančius regimuosius dirgiklius.\n",
    "\n",
    "- Be to, autoriai parodė, kad kai kurie neuronai reaguoja tik į horizontalių linijų vaizdus, o kiti - tik į skirtingų orientacijų linijas (du neuronai gali turėti tą patį recepcinį lauką, bet reaguoti į skirtingų orientacijų linijas).\n",
    "\n",
    "- Jie taip pat pastebėjo, kad kai kurie neuronai turi didesnius recepcinius laukus ir reaguoja į sudėtingesnius raštus, kurie yra žemesnio lygio raštų deriniai. \n",
    "\n",
    "- Visa tai lėmė konvoliucinio neuroninio tinklo architektūros išradimą."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konvoliucijos (koreliacijos) operacija\n",
    "\n",
    "- Konvoliucija – operatorius, kuris kaip argumentus paima dvi funkcijas $f$ ir $g$ ir grąžina trečią, kuri, tam tikra prasme, parodo $f$ ir $g$ persidengimo kiekį.\n",
    "\n",
    "- Dažniausiai viena funkcija imama kaip fiksuotas filtras, dar vadinamas branduoliu (angl. kernel).\n",
    "\n",
    "- Diskrečioms vieno kintamojo funkcijoms konvoliucijos operacija apibrėžiama kaip:\n",
    "$$\n",
    "(f * g)(m) = \\sum_{n} f(n) \\cdot g(m - n)\n",
    "$$\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"https://raw.githubusercontent.com/ugniusalekna/intro-to-ml/main/images/convolution.gif\" alt=\"convolution\" width=\"65%\">\n",
    "<p><strong>1.12 pav., Konvoliucijos operacija </strong></p>\n",
    "</div>\n",
    "\n",
    "- Šiek tiek painu: konvoliucija ir koreliacija yra labai panašios operacijos; konvoliucija yra koreliacija su filtru, pasuktu 180 laipsnių.\n",
    "\n",
    "- Kadangi filtro svoriai yra išmokstami, nėra svarbu, ar atliekant operaciją filtrą apversime, ar ne, todėl skaičiavimų prasme, lengviau atlikti koreliacijos operaciją. \n",
    "\n",
    "- Taigi, konvoliuciniai neuroniniai tinklai iš tiesų naudoja koreliaciją (angl. cross-correlation).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konvoliucinis sluoksnis\n",
    "\n",
    "- Svarbiausias struktūrinis blokas yra konvoliucinis sluoksnis – pirmojo konvoliucinio sluoksnio neuronai prijungiami ne prie kiekvieno įvesties vaizdo pikselio (kaip ankstesniuose skyriuose), o tik prie pikselių, esančių jų recepciniame lauke. \n",
    "- Savo ruožtu kiekvienas antrojo konvoliucinio sluoksnio neuronas yra sujungtas tik su neuronais, esančiais nedideliame stačiakampyje pirmajame sluoksnyje. \n",
    "- Tokia architektūra leidžia tinklui pirmajame paslėptajame sluoksnyje sutelkti dėmesį į žemo lygio požymius, tada kitame paslėptajame sluoksnyje juos surinkti į aukštesnio lygio požymius ir t.t. \n",
    "- Tokia hierarchinė struktūra būdinga vaizdo apdorojimui gyvūnų smegenyse.\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"https://raw.githubusercontent.com/ugniusalekna/intro-to-ml/main/images/receptive_field.png\" alt=\"receptive-field\" width=\"65%\">\n",
    "<p><strong>1.12 pav., Konvoliucinių sluoksnių receptinis laukas </strong></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nulių pridėjimas (angl. zero-padding)\n",
    "\n",
    "Tam tikro sluoksnio $i$ eilutėje, $j$ stulpelyje esantis neuronas yra sujungtas su ankstesnio sluoksnio neuronų, esančių nuo $i$ iki $i + f_h - 1$, nuo $j$ iki $j + f_w - 1$ eilutėse, išėjimais, kur $f_h$ ir $f_w$ yra recepcinio lauko aukštis ir plotis. Kad sluoksnis būtų tokio paties aukščio ir pločio kaip ankstesnis sluoksnis, aplink įvesties matricą reikia pridėti nulius. 1.13 pav., $5 \\times 7$ įvesties dydžio įvesties sluoksnis papildomas nulių paraštėmis iš visų pusių, kad tolimesnis sluoksnis taip pat būtų $5 \\times 7$ dydžio.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"https://raw.githubusercontent.com/ugniusalekna/intro-to-ml/main/images/zero_padding.png\" alt=\"zero-padding\" width=\"65%\">\n",
    "<p><strong>1.13 pav., Nulių pridėjimo operacija </strong></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Konvoliucijos filtro žingsnis (angl. stride)\n",
    "\n",
    "Didelės rezoliucijos įvesties sluoksniai gali būti sujungti su daug mažesnės rezoliucijos sluoksniu, išdėstant receptorinius laukus su didesniais tarpais tarp jų. Atstumas tarp dviejų vienas po kito einančių recepcinių laukų vadinamas konvoliucijos filtro žingsniu. 1.14 pav. $5 \\times 7$ įvesties sluoksnis (plius zero-pad) sujungtas su $3 \\times 4$ sluoksniu, naudojant $3 \\times 3$ recepcinius laukus ir žingsnį lygų $2$. Viršutinio sluoksnio $i$ eilutėje, $j$ stulpelyje esantis neuronas yra sujungtas su ankstesnio sluoksnio neuronų, esančių nuo $i \\times s_h$ iki $i \\times s_h + f_h - 1$ eilutėse, $j \\times s_w + f_w - 1$ stulpeliuose, išėjimais, kur $s_h$ ir $s_w$ yra žingsnių dydžiai vertikalia ir horizontalia kryptimi.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"https://raw.githubusercontent.com/ugniusalekna/intro-to-ml/main/images/stride.png\" alt=\"stride\" width=\"65%\">\n",
    "<p><strong>1.14 pav., Konvoliucijos filtro žingsnis </strong></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
