
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Dirbtiniai neuroniniai tinklai &#8212; Introductory ML Course</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/5-dirbtiniai-neuroniniai-tinklai';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Konvoliuciniai neuroniniai tinklai" href="6-konvoliuciniai-neuroniniai-tinklai.html" />
    <link rel="prev" title="Hiperplokštumomis grįsti klasifikatoriai" href="4-klasifikavimas.html" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <script type="text/javascript" id="MathJax-script" async
          src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [['$', '$']],
        processEscapes: true
      }
    });
  </script>

  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../README.html">
  
  
  
  
  
  
    <p class="title logo__title">Introductory ML Course</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../README.html">
                    Kurso santrauka
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="1-pagrindines-savokos.html">Įvadas į mašininį mokymąsi</a></li>
<li class="toctree-l1"><a class="reference internal" href="2-tiesine-regresija.html">Tolydaus kintamojo prognozės uždavinys</a></li>
<li class="toctree-l1"><a class="reference internal" href="3-truputis-teorijos.html">Truputis mašininio mokymosi teorijos</a></li>
<li class="toctree-l1"><a class="reference internal" href="4-klasifikavimas.html">Hiperplokštumomis grįsti klasifikatoriai</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Dirbtiniai neuroniniai tinklai</a></li>
<li class="toctree-l1"><a class="reference internal" href="6-konvoliuciniai-neuroniniai-tinklai.html">Konvoliuciniai neuroniniai tinklai</a></li>
<li class="toctree-l1"><a class="reference internal" href="7-generatyviniai-neuroniniai-tinklai.html">Generatyviniai neuroniniai tinklai</a></li>
<li class="toctree-l1"><a class="reference internal" href="8-pabaigai.html">Baigiamosios mintys</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li>
<button onclick="initThebeSBT()"
  class="btn btn-sm btn-launch-thebe dropdown-item"
  title="Launch Thebe"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="btn__text-container">Live Code</span>
</button>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/notebooks/5-dirbtiniai-neuroniniai-tinklai.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Dirbtiniai neuroniniai tinklai</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#matematine-formuluote">Matematinė formuluotė</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#netikties-funkcijos">Netikties funkcijos</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aktyvacijos-funkcija">Aktyvacijos funkcija</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#teoriniai-rezulatatai">Teoriniai rezulatatai</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tinklo-apmokymo-intuicija">Tinklo apmokymo intuicija</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sklidimo-atgal-algoritmas">Sklidimo atgal algoritmas</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#automatinis-diferencijavimas">Automatinis diferencijavimas</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#praktinis-taikymas-su-pytorch">Praktinis taikymas su PyTorch</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#praktine-uzduotis">Praktinė užduotis</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sprendimas">Sprendimas</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="dirbtiniai-neuroniniai-tinklai">
<h1>Dirbtiniai neuroniniai tinklai<a class="headerlink" href="#dirbtiniai-neuroniniai-tinklai" title="Link to this heading">#</a></h1>
<ul class="simple">
<li><p>Dirbtiniai neuroniniai tinklai (angl. artificial neural networks, ANNs) yra MM modelių klasė, įkvėpta smegenų neuronų architektūros.</p></li>
<li><p>Dirbtiniai neuroniniai tinklai egzistuoja jau gana seniai – pirmą kartą juos 1943 m. pristatė neurofiziologas Warrenas McCullochas ir matematikas Walteris Pittsas. Jie buvo sukurti kaip būdas aproksimuoti sudėtingas funkcijas, neturinčias aiškios išreikštinės formos.</p></li>
<li><p>Dirbtinius neuroninius tinklus sudaro sujungti mazgai, vadinami dirbtiniais neuronais. Juos jungia briaunos, atitinkančios smegenų sinapses. Kiekvienas dirbtinis neuronas gauna signalus iš prieš jį esančių neuronų, tada juos apdoroja ir siunčia signalą toliau kitiems neuronams. Signalas yra realusis skaičius, o kiekvieno neurono išvestis apskaičiuojama pagal tam tikrą taisyklę. Signalo stiprumą kiekviename ryšyje lemia svoris, dažniausiai pavaizduotas ant briaunos.</p></li>
</ul>
<hr style="border: none; height: 2px; background-color: black;">
<div style="text-align: center;">
<img src="https://raw.githubusercontent.com/ugniusalekna/intro-to-ml/main/images/real_neuron.png" alt="real-neuron" width="65%">
<p><strong>5.1 pav., Biologinis neuronas </strong></p>
</div>
<hr style="border: none; height: 2px; background-color: black;">
<ul class="simple">
<li><p>Dirbtiniai neuroniniai tinklai taikomi tiek regresijos, tiek klasifikavimo uždaviniuose.</p></li>
</ul>
<section id="matematine-formuluote">
<h2>Matematinė formuluotė<a class="headerlink" href="#matematine-formuluote" title="Link to this heading">#</a></h2>
<p>Tegul $\textbf{x} = (x_1, \ldots, x_d) \in \mathbb{R}^{d_0}$. Dirbtinis neuroninis tinklas $h^L : \mathbb{R}^{d_0} \rightarrow \mathbb{R}^d$ [čia $d = d_L$] apibrėžiamas kaip funkcijų $ h^l = (h_1^l, \ldots, h_{d_l}^l): \mathbb{R}^{d_{l-1}} \rightarrow \mathbb{R}^{d_l}, \text{ } l = 1, \ldots, L $ kompozicija, kur $h^l$ komponentės užrašomos</p>
<p>$$
h_j^1(\textbf{x}) = \sum_{i=1}^{d_0} w_{ij}^1 x_i + b_j^1, \quad j = 1, \ldots, d_1
$$</p>
<p>$$
h_j^l(\textbf{x}) = \sum_{i=1}^{d_{l-1}} w_{ij}^l \sigma(h_i^{l-1}(\textbf{x})) + b_j^l, \quad j = 1, \ldots, d_l \quad l = 2, \ldots, L
$$</p>
<ul class="simple">
<li><p>Čia $L$ žymi dirbtinio neuroninio tinklo <em>sluoksnių skaičių</em>.</p></li>
<li><p>Kiekvienas sluoksnis $l = 1, \ldots, L$ turi $d_l$ dirbtinių neuronų, $W := \max_{1 \leq l \leq L} d_l$ žymi neuroninio tinklo <em>plotį</em>.</p></li>
<li><p>Koeficientai $w_{ij}^l$ atitinka <em>svorius</em>, kurie jungia $i$-ąjį neuroną $(l-1)$-ajame sluoksnyje su $j$-uoju neuronu $l$-ajame sluoksnyje; $b_j^l$ yra $j$-ojo neurono $l$-ajame sluoksnyje <em>laisvasis narys</em>.</p></li>
<li><p>Funkcija $\sigma$, istoriškai vadinama <em>aktyvacijos funkcija</em>, yra žinoma ir fiksuota, tuo tarpu koeficientai $w_{ij}^l$ ir laisvasis narys $b_j^l$ – nežinomi.</p></li>
<li><p>MM kontekste, paskutinio sluoksnio išvestis, žymima $h^L$, yra hipotezės funkcija. Visų dirbtinio neuroninio tinklo svorių ir laisvųjų narių rinkinys vadinamas tinklo <em>parametrais</em> $\theta$. Ši parametrų aibė apibrėžia dirbtinio neuroninio tinklo architektūrą, todėl žymėsime $h^L(\textbf{x}) = h^L(\textbf{x}; \theta)$.</p></li>
</ul>
<p>Pažymėkime apmokymo aibę $D = { (\textbf{x}^{(i)}, y^i) \mid i = 1, \ldots, N}$. Tam, kad galėtume kiekybiškai įvertinti nuostolį vienai stebinio reikšmei $(\textbf{x}^{(i)}, y^i)$, įvedama nuostolių funkcija $\ell$. Norint, kad $h^L$ artinys būtų geras visoje aibėje $D$, įvedama empirinės rizikos funkcija:</p>
<p>$$
R_{emp}(h^L) = \frac{1}{N} \sum_{i=1}^{N} \ell\left( (\textbf{x}^{(i)}, y^i), h^L(\textbf{x}^{(i)};\theta) \right).
$$</p>
<ul class="simple">
<li><p>Dalykai jau pažįstami iš anksčiau :)</p></li>
</ul>
<p><em>pastaba:</em> literatūroje empirinės rizikos funkcija dažniausiai vadinama tiesiog netiktimi, sutapatinant du terminus į vieną.</p>
<section id="netikties-funkcijos">
<h3>Netikties funkcijos<a class="headerlink" href="#netikties-funkcijos" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Priklausomai nuo to, kokią netikties (empirinės rizikos) funkciją parinksime, pagal tai bus formuluojamas atitinkamas optimizavimo uždavinys. Netikties funkcijos pasirinkimas priklauso nuo problemos tipo. Pvz., regresijos užduotims dažniausiai naudojama kvadratinė netiktis, o klasifikavimo užduotims – logaritminė arba kryžminės entropijos netiktis.</p></li>
</ul>
<ol class="arabic simple">
<li><p><strong>Kvadratinė netiktis (angl. Mean Squared Error, MSE)</strong></p></li>
</ol>
<p>Kvadratinė netiktis dažniausiai naudojama regresijos užduotims spręsti. Ši funkcija skaičiuoja skirtumo tarp tikrosios reikšmės $y$ ir modelio prognozės $h^L(\textbf{x};\theta)$ kvadratą:</p>
<p>$$
\ell_{\text{MSE}}\left((\textbf{x}, y), h^L(\textbf{x};\theta)\right) = \left(y - h^L(\textbf{x};\theta)\right)^2.
$$</p>
<p>Empirinė rizika tokiu atveju bus:</p>
<p>$$
R_{\text{emp}}(h^L) = \frac{1}{N} \sum_{i=1}^{N} \left(y^{(i)} - h^L(\textbf{x}^{(i)};\theta)\right)^2.
$$</p>
<ol class="arabic simple" start="2">
<li><p><strong>Logaritminė netiktis (angl. Log Loss)</strong></p></li>
</ol>
<p>Logaritminė netiktis dažniausiai naudojama binarinės klasifikacijos uždaviniuose, kai modelis siekia nustatyti tikimybę, jog pavyzdys priklauso tam tikrai klasei:</p>
<p>$$
\ell_{\text{log}}\left((\textbf{x}, y), h^L(\textbf{x};\theta)\right) = - \left[ y \log h^L(\textbf{x};\theta) + (1 - y) \log \left(1 - h^L(\textbf{x};\theta)\right) \right].
$$</p>
<p>Empirinė rizika tokiu atveju bus:</p>
<p>$$
R_{\text{emp}}(h^L) = -\frac{1}{N} \sum_{i=1}^{N} \left[ y^{(i)} \log h^L(\textbf{x}^{(i)};\theta) + (1 - y^{(i)}) \log \left(1 - h^L(\textbf{x}^{(i)};\theta)\right) \right].
$$</p>
<ol class="arabic simple" start="3">
<li><p><strong>Kryžminės entropijos netiktis (angl. Cross-Entropy Loss)</strong></p></li>
</ol>
<p>Kryžminė entropija yra bendresnis logaritminės netikties atvejis, naudojamas daugiaklasėje klasifikacijoje. Jei turime $K$ klasių, kryžminės entropijos netiktis apibrėžiama taip:</p>
<p>$$
\ell_{\text{CE}}\left((\textbf{x}, y), h^L(\textbf{x};\theta)\right) = - \sum_{k=1}^{K} y_k \log h_k^L(\textbf{x};\theta),
$$</p>
<p>kur $y_k$ yra reikšmė, nurodanti tikrąją klasę, o $h_k^L(\textbf{x};\theta)$ yra modelio prognozuota tikimybė klasei $k$.</p>
<p>Empirinė rizika tokiu atveju bus:</p>
<p>$$
R_{\text{emp}}(h^L) = -\frac{1}{N} \sum_{i=1}^{N} \sum_{k=1}^{K} y_k^{(i)} \log h_k^L(\textbf{x}^{(i)};\theta).
$$</p>
</section>
</section>
<section id="aktyvacijos-funkcija">
<h2>Aktyvacijos funkcija<a class="headerlink" href="#aktyvacijos-funkcija" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Aktyvacijos funkcija žaidžia esminę rolę dirbtinio neuroninio tinklo architektūroje. Iš tiesų, jeigu jos nebūtų (t.y., jei $\sigma(t) = t$), tada nesvarbu kokio gylio neuroninį tinklą bekonstruosime, galutinė išraiška galės būti supaprastinta į tiesinį modelį. Aktyvacijos funkcija įveda netiesiškumo – tai leidžia modeliuoti žymiai sudėtingesnius reiškinius.</p></li>
</ul>
<div style="text-align: center;">
<img src="https://raw.githubusercontent.com/ugniusalekna/intro-to-ml/main/images/activation_functions.jpg" alt="activation-functions" width="65%">
<p><strong>5.2 pav., Dažniausiai naudojamos aktyvacijos funkcijos </strong></p>
</div>
<ul class="simple">
<li><p>Puikus puslapis, parodantis aktyvacijos funkcijos svarbą ir daug kitų aspektų: <a class="reference external" href="https://playground.tensorflow.org/#activation=tanh&amp;amp;batchSize=10&amp;amp;dataset=circle&amp;amp;regDataset=reg-plane&amp;amp;learningRate=0.03&amp;amp;regularizationRate=0&amp;amp;noise=0&amp;amp;networkShape=4,2&amp;amp;seed=0.13358&amp;amp;showTestData=false&amp;amp;discretize=false&amp;amp;percTrainData=50&amp;amp;x=true&amp;amp;y=true&amp;amp;xTimesY=false&amp;amp;xSquared=false&amp;amp;ySquared=false&amp;amp;cosX=false&amp;amp;sinX=false&amp;amp;cosY=false&amp;amp;sinY=false&amp;amp;collectStats=false&amp;amp;problem=classification&amp;amp;initZero=false&amp;amp;hideText=false">Tensorflow Playground</a></p></li>
</ul>
<section id="teoriniai-rezulatatai">
<h3>Teoriniai rezulatatai<a class="headerlink" href="#teoriniai-rezulatatai" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Aktyvacijos funkcijos svarbą pagrindžia ir kai kurie teoriniai rezultatai. Vieni pirmų teorinių rezultatų buvo atrasti austrų matematiko K. Hortnik 1989 m. Kiek vėliau, jo darbai buvo apibendrinti, įrodant teoremą, teigiančią, kad kiekvienai tolydžiai funkcijai egzistuoja dirbtinis neuroninis tinklas, gebantis aproksimuoti ją norimu tikslumu tada ir tik tada, kai aktyvacijos funkcija nėra daugianaris.</p></li>
<li><p>Labai įdomu – neuroninio tinklo idėja buvo suformuluota nemąstant iš matematinės pusės :)</p></li>
<li><p>Teoremos nenurodo apmokymo būdo, jos nurodo tik egzistavimą.</p></li>
</ul>
</section>
</section>
<section id="tinklo-apmokymo-intuicija">
<h2>Tinklo apmokymo intuicija<a class="headerlink" href="#tinklo-apmokymo-intuicija" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Dirbtinis neuroninis tinklas – sudėtinga paprastų funkcijų kompozicija.</p></li>
<li><p>Empirinės rizikos funkcija (netiktis) – matas, kaip gerai ar blogai modelis prognozuoja.</p></li>
<li><p>Svoriai ir laisvieji nariai – modelio parametrai, kuriuos galime reguliuoti.</p></li>
<li><p>Netikties funkcijos gradientas pagal kiekvieną parametrą mums nurodo, ar to parametro pokytis padidins, ar pamažins netiktį.</p></li>
</ul>
<p>Apibrėžkime nesudėtingą dviejų sluoksnių dirbtinį neuroninį tinklą:
$$
h_n(\textbf{x}) = \sum_{j=1}^{n} w_{j} \sigma\left(\sum_{i=1}^{d} w_{ij} x_i + b_j\right) + b.
$$</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">two_layer_nn</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">activation</span><span class="p">):</span>

    <span class="n">z1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W1</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">+</span> <span class="n">b1</span>   <span class="c1"># Shape (m, n)</span>
    <span class="n">a1</span> <span class="o">=</span> <span class="n">activation</span><span class="p">(</span><span class="n">z1</span><span class="p">)</span>         <span class="c1"># Shape (m, n)</span>
    <span class="n">z2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">a1</span><span class="p">,</span> <span class="n">W2</span><span class="p">)</span> <span class="o">+</span> <span class="n">b2</span>    <span class="c1"># Shape (m,)</span>
    
    <span class="k">return</span> <span class="n">z2</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">identity</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">x_seq</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y_seq</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x_seq</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_html">
        <iframe
            width="100%"
            height="650"
            src="http://127.0.0.1:8054/"
            frameborder="0"
            allowfullscreen
            
        ></iframe>
        </div></div>
</div>
</section>
<section id="sklidimo-atgal-algoritmas">
<h2>Sklidimo atgal algoritmas<a class="headerlink" href="#sklidimo-atgal-algoritmas" title="Link to this heading">#</a></h2>
<p>Neuroniniai tinklai apmokomi minimizuojant empirinės rizikos funkciją. Minimizavimas dažniausiai atliekamas gradientinio nusileidimo metodais. Taikant šiuos metodus, reikia apskaičiuoti empirinės rizikos funkcijos gradientą.</p>
<p>1986 m. Davidas Rumelhartas, Geoffrey Hintonas ir Ronaldas Williamsas išleido straipsnį, kuriame buvo pristatytas sklidimo atgal apmokymo algoritmas (angl. backpropagation), kuris naudojamas iki šiol.</p>
<p>Algoritmas yra efektyvus, nes tik per du perėjimus per tinklą (vieną pirmyn, kitą atgal) galima apskaičiuoti empirinės rizikos funkcijos gradientą kiekvieno modelio parametro atžvilgiu.</p>
<div style="text-align: center;">
<img src="https://raw.githubusercontent.com/ugniusalekna/intro-to-ml/main/images/backprop.png" alt="backprop" width="65%">
<p><strong>5.3 pav., Sklidimo atgal algoritmas </strong></p>
</div><p>Iki šiol, gradientus apskaičiuodavome apibrėždami juos iš anksto pagal tam tikras formules. Tai veikė gerai, kadangi turimi modeliai buvo stacionarūs (pvz., tiesinės regresijos hipotezė visada tokia pati, todėl galime apibrėžti empirinės rizikos funkcijos gradientą ir ją naudoti optimizavime). Dirbtiniai neuroniniai tinklai, kita vertus, yra labai universalūs, gali būti didinami bei mažinami (plotis, gylis), todėl apibrėžti gradiento negalime.</p>
<p>Skaitiškai apskaičiuoti funkcijos išvestinę yra daug būdų, pavyzdžiui:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span>

<span class="k">def</span> <span class="nf">diff</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">h</span><span class="p">)</span> <span class="o">-</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">/</span> <span class="n">h</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">diff</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>

<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;f(x)&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;f&#39;(x)&quot;</span><span class="p">)</span>

<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Function x^2&quot;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Derivative of x^2&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">axs</span><span class="p">:</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/f14321ff309b6acab5668646758fdf8125f808596ca80f564c37c5259bedb524.png" src="../_images/f14321ff309b6acab5668646758fdf8125f808596ca80f564c37c5259bedb524.png" />
</div>
</div>
<ul class="simple">
<li><p>Bendru atveju toks būdas nėra efektyvus ir labai lėtai veikiantis.</p></li>
<li><p>Gradientai yra apskaičiuojami taikant automatinio diferencijavimo (angl. autodiff) algoritmą.</p></li>
</ul>
<section id="automatinis-diferencijavimas">
<h3>Automatinis diferencijavimas<a class="headerlink" href="#automatinis-diferencijavimas" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Automatinis diferencijavimas (AD) naudojamas apskaičiuoti kompiuteriu užrašomų funkcijų dalines išvestines. Metodo veikimas paremtas tuo, jog visi skaitiniai skaičiavimai gali būti suvesti į baigtinį skaičių elementarių operacijų, kurių išvestinės yra žinomos. Žinodami sudedamųjų operacijų išvestines bei pasinaudodami sudėtinės funkcijos diferencijavimo taisykle, galime tiksliai apskaičiuoti norimos funkcijos dalines išvestines pasirinktame taške.</p></li>
<li><p>AD atliekamas dviem etapais: pirmuoju etapu apskaičiuojamos visų sudedamųjų operacijų vertės, o antruoju etapu apskaičiuojamos išvestinės. Algoritmo veikimą pavaizduosime pavyzdžiu.</p></li>
</ul>
<p>Nagrinėkime dviejų kintamųjų funkciją $f(x_1, x_2) = \frac{3}{1 + \text{e}^{-(2x_1 - 3x_2 + 2)}} - 1$ (<em>pastaba</em>: toks funkcijos pasirinkimas neatsitiktinis – atkreipkite dėmesį į neuroninio tinklo išraišką). Tuomet $f$ galime užrašyti kaip funkcijų $h_1: \mathbb{R}^2 \rightarrow \mathbb{R}, h_2: \mathbb{R} \rightarrow \mathbb{R}, h_3: \mathbb{R} \rightarrow \mathbb{R}$ kompoziciją, $f = h_3 \circ h_2 \circ h_1$, kur $h_1(x, y) = 2x - 3y + 2$, $h_2(x) = \frac{1}{1 + \text{e}^{-x}}$, $h_3(x) = 3x - 1$. Apskaičiuosime funkcijos $f$ dalines išvestines $\frac{\partial f}{\partial x_1}$, $\frac{\partial f}{\partial x_2}$ taške $(x_1, x_2) = (0.5, 1)$:</p>
<div style="text-align: center;">
<img src="https://raw.githubusercontent.com/ugniusalekna/intro-to-ml/main/images/backprop_example.png" alt="backprop-example" width="65%">
<p><strong>5.4 pav., Sklidimo atgal algoritmo pavyzdys </strong></p>
</div>
<p>Galime pastebėti, kad atlikę vieną sklidimo į priekį ir vieną atgalinio sklidimo etapą, randame visas funkcijos $f:\mathbb{R}^d \rightarrow \mathbb{R}$ dalines išvestines, nepriklausomai nuo kintamųjų skaičiaus $d$, t.y. algoritmo skaičiavimo sudėtingumas priklauso tik nuo pačios funkcijos sudėtingumo.</p>
<p>Sklidimo į priekį metu apskaičiuojamos vertės išsaugomos grafe (angl. computational graph); tuomet, sklidimo atgal metu išsaugomos dalinės išvestinės. Pabaigus vieną skaičiavimo ciklą bei skaičiuojant gradientus naujoje iteracijoje, būtina nunulinti gradientų reikšmes, nes kitaip jos kaupsis.</p>
<div style="text-align: center;">
<img src="https://raw.githubusercontent.com/ugniusalekna/intro-to-ml/main/images/computational_graph.png" alt="computational-graph" width="100%">
<p><strong>5.5 pav., Automatinio diferencijavimo grafas</strong></p>
</div></section>
</section>
<section id="praktinis-taikymas-su-pytorch">
<h2>Praktinis taikymas su PyTorch<a class="headerlink" href="#praktinis-taikymas-su-pytorch" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Nuo šiol modeliams kurti naudosime PyTorch. Jis pasirūpins sklidimo atgal algoritmu ir automatiniu diferencijavimu, todėl mums tereiks apibrėžti neuroninio tinklo architektūrą!</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>


<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">channels_in</span><span class="p">,</span> <span class="n">channels_hidden</span><span class="p">,</span> <span class="n">channels_out</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">channels_in</span><span class="p">,</span> <span class="n">channels_hidden</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">channels_hidden</span><span class="p">,</span> <span class="n">channels_out</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_seq</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y_seq</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x_seq</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.25</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Net</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">log_interval</span> <span class="o">=</span> <span class="n">num_epochs</span> <span class="o">//</span> <span class="mi">10</span>
    
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_seq</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">y_seq</span><span class="p">)</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            
        <span class="n">avg_epoch_loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        
        <span class="k">if</span> <span class="ow">not</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">log_interval</span> <span class="ow">or</span> <span class="n">epoch</span><span class="o">+</span><span class="mi">1</span> <span class="o">==</span> <span class="n">num_epochs</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1"> loss </span><span class="si">{</span><span class="n">avg_epoch_loss</span><span class="si">:</span><span class="s1">.04f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        
<span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 0 loss 0.6411
Epoch 50 loss 0.2323
Epoch 100 loss 0.1460
Epoch 150 loss 0.1269
Epoch 200 loss 0.1220
Epoch 250 loss 0.1194
Epoch 300 loss 0.1174
Epoch 350 loss 0.1157
Epoch 400 loss 0.1139
Epoch 450 loss 0.1119
Epoch 499 loss 0.1097
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_seq</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_seq</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">y_seq</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Data samples&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_seq</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">predictions</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#FF5B00&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Network prediction&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Simple network predictions&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Input (x)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Output (y)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/a964552cfe72c049be024d5b495b3003112760849611199b82c66c1fe1982f85.png" src="../_images/a964552cfe72c049be024d5b495b3003112760849611199b82c66c1fe1982f85.png" />
</div>
</div>
</section>
<section id="praktine-uzduotis">
<h2>Praktinė užduotis<a class="headerlink" href="#praktine-uzduotis" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Naudodamiesi paskaitos žiniomis, sukurkite paprastą dirbtinį neuroninį tinklą naudojant <code class="docutils literal notranslate"><span class="pre">PyTorch</span></code> biblioteką.</p></li>
<li><p>Duomenų aibę sudaro $(\textbf{X}, y) \in \mathbb{R}^2 \times \{ 0, 1 \} $, taigi, dirbtinis neuroninis tinklas bus hipotezė, skirta klasifikavimo uždaviniui spręsti.</p></li>
<li><p>Esminiai aspektai:</p>
<ul>
<li><p>Sukurkite <code class="docutils literal notranslate"><span class="pre">torch.utils.data.Dataset</span></code> klasę duomenų įkėlimui ir paruošimui.</p></li>
<li><p>Apibrėžkite dirbtinio neuroninio tinklo architektūrą pasinaudoję <code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code> klase. Modelyje turi būti keli tiesiniai sluoksniai (<code class="docutils literal notranslate"><span class="pre">torch.nn.Linear</span></code>), aktyvacijos funkcija (<code class="docutils literal notranslate"><span class="pre">torch.nn.ReLU</span></code>).</p></li>
<li><p>Parašykite tinko apmokymo ciklo funkciją. Naudokite tinkamą nuostolių funkciją (<code class="docutils literal notranslate"><span class="pre">torch.nn.CrossEntropyLoss</span></code>) ir optimizatorių (<code class="docutils literal notranslate"><span class="pre">torch.optim.Adam</span></code>). Kiekvienos epochos pabaigoje atlikite validavimą, kad galėtumėte stebėti modelio generalizaciją nematytiems duomenims ir išvengtumėte persimokymo.</p></li>
<li><p>Įvertinkite modelio efektyvumą naudojant validacijos rinkinį ir pasirinktą tikslumo metriką.</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_moons</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_moons</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Paired</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Make Moons Data&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/fcc4ade66731b3d463fbef58c90dc07a19e79c47d6e963f41c385600ebe092a8.png" src="../_images/fcc4ade66731b3d463fbef58c90dc07a19e79c47d6e963f41c385600ebe092a8.png" />
</div>
</div>
<section id="sprendimas">
<h3>Sprendimas<a class="headerlink" href="#sprendimas" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">MoonsDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">MoonsDataset</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">val_dataset</span> <span class="o">=</span> <span class="n">MoonsDataset</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">val_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="n">input_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">output_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Net</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">train_losses</span><span class="p">,</span> <span class="n">val_losses</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="n">log_interval</span> <span class="o">=</span> <span class="mi">10</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">running_loss_train</span> <span class="o">=</span> <span class="n">running_loss_val</span> <span class="o">=</span> <span class="mf">0.0</span>
    
    <span class="k">for</span> <span class="n">inputs_train</span><span class="p">,</span> <span class="n">labels_train</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>

        <span class="n">outputs_train</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs_train</span><span class="p">)</span>
        <span class="n">loss_train</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs_train</span><span class="p">,</span> <span class="n">labels_train</span><span class="p">)</span>
        
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss_train</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        
        <span class="n">running_loss_train</span> <span class="o">+=</span> <span class="n">loss_train</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            
    <span class="n">train_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">running_loss_train</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">))</span>
    
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">inputs_val</span><span class="p">,</span> <span class="n">labels_val</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
            <span class="n">outputs_val</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs_val</span><span class="p">)</span>
            <span class="n">loss_val</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs_val</span><span class="p">,</span> <span class="n">labels_val</span><span class="p">)</span>
            
            <span class="n">running_loss_val</span> <span class="o">+=</span> <span class="n">loss_val</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        
        <span class="n">val_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">running_loss_val</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="p">))</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">log_interval</span> <span class="ow">or</span> <span class="n">epoch</span><span class="o">+</span><span class="mi">1</span> <span class="o">==</span> <span class="n">num_epochs</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch [</span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s2">]; Train Loss: </span><span class="si">{</span><span class="n">train_losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">; Validation Loss: </span><span class="si">{</span><span class="n">val_losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [10/100]; Train Loss: 0.3067; Validation Loss: 0.2824
Epoch [20/100]; Train Loss: 0.2345; Validation Loss: 0.2072
Epoch [30/100]; Train Loss: 0.1824; Validation Loss: 0.1581
Epoch [40/100]; Train Loss: 0.1427; Validation Loss: 0.1214
Epoch [50/100]; Train Loss: 0.1163; Validation Loss: 0.1011
Epoch [60/100]; Train Loss: 0.1010; Validation Loss: 0.0880
Epoch [70/100]; Train Loss: 0.0927; Validation Loss: 0.0802
Epoch [80/100]; Train Loss: 0.0881; Validation Loss: 0.0776
Epoch [90/100]; Train Loss: 0.0842; Validation Loss: 0.0744
Epoch [100/100]; Train Loss: 0.0837; Validation Loss: 0.0714
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">epochs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">train_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training Loss&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_losses</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#FF5B00&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation Loss&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Training and Validation Loss Over Epochs&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ea6cfef0909ec582628558bebb3bde023d014bec16576f6bc5dd1fd9177c212e.png" src="../_images/ea6cfef0909ec582628558bebb3bde023d014bec16576f6bc5dd1fd9177c212e.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">all_preds</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">all_preds</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">predicted</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>


<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span> <span class="n">all_preds</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Final Validation Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Final Validation Accuracy: 98.00%
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mf">0.5</span>
<span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mf">0.5</span>
<span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">))</span>

<span class="n">grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()]</span>
<span class="n">grid_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">grid_tensor</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">Z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">axs</span><span class="p">:</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Paired</span><span class="p">)</span>

<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Paired</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Train dataset&quot;</span><span class="p">)</span>

<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_val</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_val</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_val</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Paired</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Validation dataset&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Decision Boundaries&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/9edd5c41b9bd5e395bb6e063000d5cbb25f166c744351053550a10e647045bf5.png" src="../_images/9edd5c41b9bd5e395bb6e063000d5cbb25f166c744351053550a10e647045bf5.png" />
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "ugniusalekna/intro-to-ml",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "docs/notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="4-klasifikavimas.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Hiperplokštumomis grįsti klasifikatoriai</p>
      </div>
    </a>
    <a class="right-next"
       href="6-konvoliuciniai-neuroniniai-tinklai.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Konvoliuciniai neuroniniai tinklai</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#matematine-formuluote">Matematinė formuluotė</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#netikties-funkcijos">Netikties funkcijos</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aktyvacijos-funkcija">Aktyvacijos funkcija</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#teoriniai-rezulatatai">Teoriniai rezulatatai</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tinklo-apmokymo-intuicija">Tinklo apmokymo intuicija</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sklidimo-atgal-algoritmas">Sklidimo atgal algoritmas</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#automatinis-diferencijavimas">Automatinis diferencijavimas</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#praktinis-taikymas-su-pytorch">Praktinis taikymas su PyTorch</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#praktine-uzduotis">Praktinė užduotis</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sprendimas">Sprendimas</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By ugniusalekna
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>